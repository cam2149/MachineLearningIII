{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97150b0c-59b5-4eec-9d05-794210b0d25b",
   "metadata": {},
   "source": [
    "## Selección de caracteristicas\n",
    "**Considera la siguiente pregunta**:  Dado un gran conjunto de datos (más de 1000 columnas con 10,000 filas (registros)), ¿cómo seleccionas las características útiles para construir un modelo supervisado?\n",
    "\n",
    "De hecho, no hay una solución absoluta para esta pregunta, sino que está diseñada para probar tu capacidad de razonamiento lógico y habilidad de explicación.\n",
    "\n",
    "Para complementar lo realizado en la clase de hoy, abordaremos una tarea diferente. Esta tarea tiene como objetivo predecir el nivel de riesgo (suscripción) del solicitante de seguro de vida. \n",
    "\n",
    "**Contexto**\n",
    "\n",
    "Eres un científico de datos en una *start-up* con el potencial de tener un impacto muy grande en el negocio. Estás respaldado por una empresa con 140 años de experiencia en negocios.\n",
    "\n",
    "\n",
    "*Prudential*, uno de los mayores emisores de seguros de vida en los EE. UU., está contratando científicos de datos apasionados para unirse a un grupo recién formado de Ciencia de Datos, resolviendo desafíos complejos e identificando oportunidades. Los resultados hasta ahora han sido impresionantes, pero queremos más.\n",
    "\n",
    "**El reto**: En un mundo de compras con un clic y todo bajo demanda, el proceso de solicitud de seguro de vida es anticuado. Los clientes proporcionan información extensa para identificar la clasificación de riesgo y la elegibilidad, incluyendo la programación de exámenes médicos, un proceso que toma un promedio de 30 días.\n",
    "\n",
    "*¿El resultado?* La gente se desanima. Es por eso que solo el 40% de los hogares en EE. UU. tiene un seguro de vida individual. Prudential quiere hacer que sea más rápido y menos laborioso para los nuevos y actuales clientes obtener una cotización, manteniendo los límites de privacidad.\n",
    "\n",
    "Al desarrollar un modelo predictivo que clasifique con precisión el riesgo utilizando un enfoque más automatizado, puedes impactar enormemente la percepción pública de la industria.\n",
    "\n",
    "Los resultados ayudarán a Prudential a comprender mejor el poder predictivo de los puntos de datos en la evaluación actual, permitiéndonos simplificar significativamente el proceso.\n",
    "\n",
    "mayores detalles se pueden encontrar en la descripción del dataset: [prudential dataset](https://www.kaggle.com/c/prudential-life-insurance-assessment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871d21a3-cee1-4dfe-9cb1-cc69ea5bfff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(style='darkgrid')\n",
    "\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c360f5c-37e5-4901-95dc-b25edb793b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.148536</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>E1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.288703</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>D2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.234310</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "Id                                                                  \n",
       "2                1             D3              10        0.076923   \n",
       "5                1             A1              26        0.076923   \n",
       "6                1             E1              26        0.076923   \n",
       "7                1             D4              10        0.487179   \n",
       "8                1             D2              26        0.230769   \n",
       "\n",
       "    Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n",
       "Id                                                                       \n",
       "2                2               1               1  0.641791  0.581818   \n",
       "5                2               3               1  0.059701  0.600000   \n",
       "6                2               3               1  0.029851  0.745455   \n",
       "7                2               3               1  0.164179  0.672727   \n",
       "8                2               3               1  0.417910  0.654545   \n",
       "\n",
       "          Wt  ...  Medical_Keyword_40  Medical_Keyword_41  Medical_Keyword_42  \\\n",
       "Id            ...                                                               \n",
       "2   0.148536  ...                   0                   0                   0   \n",
       "5   0.131799  ...                   0                   0                   0   \n",
       "6   0.288703  ...                   0                   0                   0   \n",
       "7   0.205021  ...                   0                   0                   0   \n",
       "8   0.234310  ...                   0                   0                   0   \n",
       "\n",
       "    Medical_Keyword_43  Medical_Keyword_44  Medical_Keyword_45  \\\n",
       "Id                                                               \n",
       "2                    0                   0                   0   \n",
       "5                    0                   0                   0   \n",
       "6                    0                   0                   0   \n",
       "7                    0                   0                   0   \n",
       "8                    0                   0                   0   \n",
       "\n",
       "    Medical_Keyword_46  Medical_Keyword_47  Medical_Keyword_48  Response  \n",
       "Id                                                                        \n",
       "2                    0                   0                   0         8  \n",
       "5                    0                   0                   0         4  \n",
       "6                    0                   0                   0         8  \n",
       "7                    0                   0                   0         8  \n",
       "8                    0                   0                   0         8  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59381, 126)\n",
      "(59381,)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.set_index('Id', inplace=True)\n",
    "display(train_df.head())\n",
    "X_train, y_train = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29df7c75-49f3-4a06-a044-c40b97aaca7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "2        8\n",
       "5        4\n",
       "6        8\n",
       "7        8\n",
       "8        8\n",
       "        ..\n",
       "79142    4\n",
       "79143    7\n",
       "79144    8\n",
       "79145    8\n",
       "79146    7\n",
       "Name: Response, Length: 59381, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84dca93-fe2e-4d29-bafd-92e424994722",
   "metadata": {},
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9e966-256b-4d80-bfa1-ea31b3bde939",
   "metadata": {},
   "source": [
    "## Limpieza de datos sencilla\n",
    "\n",
    "Aquí realizamos una limpieza de datos sencilla. Por ejemplo, La mayoría de las implementaciones de modelos de aprendizaje automático no aceptan entradas de tipo cadena, por lo que debemos transformarlas en valores numéricos.\n",
    "\n",
    "Actividad: analizar el siguiente proceso de limpieza de datos y documentar cada etapa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c8e0067-e22e-470a-8886-2eddc456a113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A7': 0, 'D1': 1, 'B1': 2, 'C2': 3, 'C1': 4, 'D2': 5, 'A8': 6, 'A2': 7, 'D3': 8, 'C3': 9, 'A3': 10, 'C4': 11, 'A1': 12, 'E1': 13, 'A4': 14, 'D4': 15, 'B2': 16, 'A5': 17, 'A6': 18}\n",
      "containing NA values: Employment_Info_1\n",
      "containing NA values: Employment_Info_4\n",
      "containing NA values: Employment_Info_6\n",
      "containing NA values: Insurance_History_5\n",
      "containing NA values: Family_Hist_2\n",
      "containing NA values: Family_Hist_3\n",
      "containing NA values: Family_Hist_4\n",
      "containing NA values: Family_Hist_5\n",
      "containing NA values: Medical_History_1\n",
      "containing NA values: Medical_History_10\n",
      "containing NA values: Medical_History_15\n",
      "containing NA values: Medical_History_24\n",
      "containing NA values: Medical_History_32\n"
     ]
    }
   ],
   "source": [
    "ordinal_y_mean_dict = {}\n",
    "\n",
    "#\n",
    "for col in X_train.select_dtypes(include='object').columns:\n",
    "    ordinal_y_mean_dict[col]  = {index:i for i, index in enumerate(train_df.groupby(col)['Response'].mean().sort_values().index)}\n",
    "    print(ordinal_y_mean_dict[col])\n",
    "    X_train[col] = X_train[col].map(ordinal_y_mean_dict[col])\n",
    "    \n",
    "#\n",
    "for col in X_train:\n",
    "    if pd.isnull(X_train[col]).any():\n",
    "        print('containing NA values:', col)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train2 = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "#\n",
    "for col in X_train2:\n",
    "    if pd.isnull(X_train2[col]).any():\n",
    "        print('containing NA values:', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cc74cb-add1-4c2d-baa9-3b6058a8fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## crear una copia\n",
    "X_train2_unsup  = X_train2.copy() #deep copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9149d-b7ba-461d-9ba4-7a41b40c81a9",
   "metadata": {},
   "source": [
    "\n",
    "**Drop by the missing rate**\n",
    "\n",
    "Eliminar columnas con una alta tasa de valores faltantes. El primer y más fácil enfoque es eliminar columnas en el enfoque no supervisado. Podemos eliminar columnas que tengan demasiados valores faltantes.\n",
    "Consultar el uso de ``dropna``\n",
    "\n",
    "\n",
    "**Drop by the variance**\n",
    "\n",
    "Eliminar columnas con una varianza pequeña. Otra forma es eliminar columnas con una varianza demasiado pequeña, ya que estas columnas generalmente aportan poca información. Consultar el uso de ``VarianceThreshold``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1e176-44b8-47bb-bf7c-ea0c2908524c",
   "metadata": {},
   "source": [
    "**Supervised approach**\n",
    "\n",
    "Un enfoque más sofisticado es hacerlo mediante aprendizaje supervisado. *Selección de características por modelo*. Algunos modelos de aprendizaje automático están diseñados para la selección de características, como la regresión lineal basada en L1 y los Árboles Extremadamente Aleatorizados ( Extra-trees model). En comparación con la regularización L2, la regularización L1 tiende a forzar los parámetros de las características no importantes a cero. (¿Sabes por qué?) Los árboles extremadamente aleatorizados dividen las hojas de manera aleatoria (no a través de la ganancia de información o la entropía). Las características importantes deberían seguir siendo más relevantes que las características no importantes (medidas por la importancia de características basada en la impureza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24a52d1-b9d0-4d15-b0a6-cc41fb9e743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_sup = X_train2.copy() #deep copy\n",
    "\n",
    "X_model, X_valid, y_model, y_valid = train_test_split(X_train2_sup, y_train, stratify=y_train, random_state=random_state, test_size=.8)\n",
    "\n",
    "model_dict = {'LogisticRegression': LogisticRegression(penalty='l1', solver='saga', C=2, multi_class='multinomial', n_jobs=-1, random_state=random_state)\n",
    "             , 'ExtraTreesClassifier': ExtraTreesClassifier(n_estimators=200, max_depth=3, min_samples_leaf=.06, n_jobs=-1, random_state=random_state)\n",
    "              , 'RandomForestClassifier': RandomForestClassifier(n_estimators=20, max_depth=2, min_samples_leaf=.1, random_state=random_state, n_jobs=-1)\n",
    "             }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b48d9-ca4a-412e-9f61-040adddc6ebd",
   "metadata": {},
   "source": [
    "si el modelo es ``ExtraTreesClassifier`` o ``RandomForestClassifier``\n",
    "\n",
    "importance_values = model.feature_importances_\n",
    "\n",
    "\n",
    "Si el modelo es ``LogisticRegression``\n",
    "\n",
    "importance_values = np.absolute(model.coef_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0723b-6be5-490e-80f2-d1862d0f133d",
   "metadata": {},
   "source": [
    "**Actividad**:  \n",
    " 1. evaluar el modelo con todas las carácteristicas\n",
    " 2. evaluar el modelo con las primeras 10 carácteristicas\n",
    " 3. evaluar el modelo con las primeras 20 carácteristicas\n",
    " 4. Observa cambios significativos en el rendimiento de los modelos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffdd209-4d78-444a-b26c-dd323a0090ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e838594b-3dee-4cde-bf36-1a14ccb35e25",
   "metadata": {},
   "source": [
    "**Eliminación Recursiva de Características (RFE)**. La segunda parte consiste en seleccionar la mejor combinación de características. Lo hacemos mediante la \"Eliminación Recursiva de Características\" (RFE). En lugar de construir un solo modelo, construimos n modelos (donde n = el número de características). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64951277-9cc4-439a-a3c3-1da8c5c4f307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc1f5e5-3bc4-49c1-99aa-4e430e4af089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a18a9-ada2-4704-a6e6-d2cf55ed7b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
